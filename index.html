<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ContextNav</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">ContextNav: Towards Agentic Multimodal In-Context Learning</h1>

          <!-- 作者 + 小标 -->
          <div class="is-size-5 publication-authors">
            <span class="author-block"><p>Honghao Fu<sup>1</sup>,</p></span>
            <span class="author-block"><p>Ouyang Yuan<sup>2</sup>,</p></span>
            <span class="author-block"><p>Kai-Wei Chang<sup>3</sup>,</p></span>
            <span class="author-block"><p>Yiwei Wang<sup>4</sup>,</p></span>
            <span class="author-block"><p>Zi Huang<sup>1</sup>,</p></span>
            <span class="author-block"><p>Yujun Cai<sup>1,†</sup></p></span>
          </div>

          <!-- 机构列表 -->
          <div class="is-size-6 publication-authors">
            <p><sup>1</sup>The University of Queensland &nbsp;&nbsp;
               <sup>2</sup>Nanjing University &nbsp;&nbsp;
               <sup>3</sup>University of California, Los Angeles &nbsp;&nbsp;
               <sup>4</sup>University of California, Merced
            </p>
          </div>

          <!-- 对应标注 -->
          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>†</sup>Corresponding Author</span>
          </div>

          <!-- 链接区 -->
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code (Coming Soon)</span>
                </a>
              </span>
              <span class="link-block">
                <a href="" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p> Recent advances demonstrate that multimodal large language models (MLLMs) exhibit strong multimodal in-context learning (ICL) capabilities, enabling them to adapt to novel vision-language tasks from a few contextual examples. However, existing ICL approaches face challenges in reconciling scalability with robustness across diverse tasks and noisy contextual examples: manually selecting examples produces clean contexts but is labor-intensive and task-specific, while similarity-based retrieval improves scalability but could introduce irrelevant or structurally inconsistent samples that degrade ICL performance. To address these limitations, we propose ContextNav, the first agentic framework that integrates the scalability of automated retrieval with the quality and adaptiveness of human-like curation, enabling noise-robust and dynamically optimized contextualization for multimodal ICL. <strong>ContextNav</strong> unifies context management and noise-robust contextualization within a closed-loop workflow driven by graph-based orchestration. Specifically, it builds a resource-aware multimodal embedding pipeline, maintains a retrievable vector database, and applies agentic retrieval and structural alignment to construct noise-resilient contexts. An Operational Grammar Graph (OGG) further supports adaptive workflow planning and optimization, enabling the agent to refine its operational strategies based on downstream ICL feedback. Experimental results demonstrate that ContextNav achieves state-of-the-art performance across various datasets, underscoring the promise of agentic workflows for advancing scalable and robust contextualization in multimodal ICL. </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

  <section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Motivation</h2>
        <div class="content has-text-justified">
          <figure style="margin: 2rem auto; max-width: 100%;">
            <img src="./static/images/moti.png"
                 alt="Paper Preview"
                 style="width: 100%; height: auto; display: block; margin: 0 auto;">
            <figcaption class="has-text-justified"
                        style="font-style: normal; margin-top: 1rem; font-size: 0.9rem; line-height: 1.5;">
              <p style="margin-bottom: 0.8rem;">
              <strong>Motivation for introducing agentic contextualization in multimodal ICL.</strong> Similarity-based retrieval can introduce semantic or structural noise into contextual candidates, which degrades ICL effectiveness. Employing an agent for human-like curation could effectively alleviate this challenge.              </p>
            </figcaption>
          </figure>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <figure style="margin: 2rem auto; max-width: 100%;">
            <img src="./static/images/framework.png"
                 alt="Paper Preview"
                 style="width: 100%; height: auto; display: block; margin: 0 auto;">
            <figcaption class="has-text-justified"
                        style="font-style: normal; margin-top: 1rem; font-size: 0.9rem; line-height: 1.5;">
              <p style="margin-bottom: 0.8rem;">
                <strong>Framework of the ContextNav.</strong> The proposed agentic framework integrates three synergistic modules: (a) <strong>Agentic Context Management</strong>, which performs resource-aware multimodal embedding, maintains a continuously updated vector database, and subsequently leverages it for similarity-based retrieval to generate the initial candidate pool given an input query; (b) <strong>Noise-Robust Contextualization</strong>, which refines retrieved candidates through agentic retrieval and structural alignment to mitigate both semantic and structural noise; and (c) <strong>Graph-driven Workflow Orchestration</strong>, where the agent leverages an Operational Grammar Graph and memory module to adaptively plan and optimize operation sequence, thereby controlling the workflow. Collectively, these modules enable systematic management, representation, retrieval, and organization of multimodal contexts, supporting noise-robust and dynamically optimized contextualization for multimodal ICL.
              </p>
            </figcaption>
          </figure>
        </div>
      </div>
    </div>
  </div>
</section>




<!-- <style>
  .math-notation {
    font-family: "Times New Roman", Times, serif;
  }
</style> -->

<!-- 问题选择按钮 -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        ----

      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
